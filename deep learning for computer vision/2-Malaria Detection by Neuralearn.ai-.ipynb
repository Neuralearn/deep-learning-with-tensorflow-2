{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rR4jSKq1m4WT"},"outputs":[],"source":["import tensorflow as tf### models\n","import numpy as np### math computations\n","import matplotlib.pyplot as plt### plots\n","import sklearn### machine learning library\n","import cv2## image processing\n","from sklearn.metrics import confusion_matrix, roc_curve### metrics\n","import seaborn as sns### visualizations\n","import datetime\n","import io\n","import os\n","import random\n","from google.colab import files\n","from PIL import Image\n","import albumentations as A\n","import tensorflow_datasets as tfds\n","import tensorflow_probability as tfp\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input, Dropout, RandomFlip, RandomRotation, Resizing, Rescaling\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tensorflow.keras.metrics import BinaryAccuracy, FalsePositives, FalseNegatives, TruePositives, TrueNegatives, Precision, Recall, AUC, binary_accuracy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.regularizers  import L2, L1\n","from tensorboard.plugins.hparams import api as hp\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"iFJwm1uxmRez"},"source":["## Wandb Install, Login, Initialization and Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SGRTsq6Nqzrm","outputId":"b431d52f-09da-44f2-e630-5093aea605e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17486,"status":"ok","timestamp":1663064983236,"user":{"displayName":"Md. Asif Bin Khaled","userId":"12341681592563429881"},"user_tz":-360},"id":"Fy2mEFDzpKwL","outputId":"c2ddf590-87fd-428d-f308-48839220704c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 27.1 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 64.4 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 56.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 8.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 63.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 57.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 58.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 58.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 57.4 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 62.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 56.0 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=2e9b4ce856f8fd3e8af4d8092d480ae0e5fb73e6183da07d38081b80ba4b350c\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7M99wtkhAT9"},"outputs":[],"source":["import wandb\n","from wandb.keras import WandbCallback"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"_-sLU81XmSBx","outputId":"5addff8c-aec5-4203-8b58-339fd257cca9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "]}],"source":["!wandb login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yn6EL3iOtSbq"},"outputs":[],"source":["wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\")\n","\n","###wandb.tensorboard.patch(root_logdir=\"./logs\")\n","#wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\", sync_tensorboard=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKjsIPdavgSE"},"outputs":[],"source":["wandb.config = {\n","  \"LEARNING_RATE\": 0.001,\n","  \"N_EPOCHS\": 5,\n","  \"BATCH_SIZE\": 128,\n","  \"DROPOUT_RATE\": 0.0,\n","  \"IM_SIZE\": 224,\n","  \"REGULARIZATION_RATE\": 0.0,\n","  \"N_FILTERS\": 6,\n","  \"KERNEL_SIZE\": 3,\n","  \"N_STRIDES\": 1,\n","  \"POOL_SIZE\": 2,\n","  \"N_DENSE_1\": 100,\n","  \"N_DENSE_2\": 10,\n","}\n","CONFIGURATION = wandb.config"]},{"cell_type":"markdown","metadata":{"id":"HrGMGJ7Nb3Bh"},"source":["# Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"DK7_p02_b6_m"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"899Bnj-olJGx"},"outputs":[],"source":["dataset, dataset_info = tfds.load('malaria', with_info=True,\n","                                  as_supervised=True, \n","                                  shuffle_files = True, \n","                                  split=['train'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XixoxMwuKG_-"},"outputs":[],"source":["for data in dataset[0].take(1):\n","  print(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syf8XttCCWzX"},"outputs":[],"source":["for i in d.take(1):\n","  print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPBOQ3B_cIpx"},"outputs":[],"source":["#dataset_info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZF9ACbZwHhm3"},"outputs":[],"source":["def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):\n","  DATASET_SIZE = len(dataset)\n","\n","  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))\n","\n","  val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))\n","  val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))\n","\n","  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))\n","  return train_dataset, val_dataset, test_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUiEq8Ew9AwN"},"outputs":[],"source":["TRAIN_RATIO = 0.8\n","VAL_RATIO = 0.1\n","TEST_RATIO = 0.1\n","\n","train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO )\n","#print(list(train_dataset.take(1).as_numpy_iterator()),\n"," #     list(val_dataset.take(1).as_numpy_iterator()), list(test_dataset.take(1).as_numpy_iterator()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5otp5EUU2cy"},"outputs":[],"source":["train_datasets"]},{"cell_type":"markdown","metadata":{"id":"-1QWh3KjbsuJ"},"source":["## Dataset Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7l7Lre1oUzx2"},"outputs":[],"source":["for i, (image, label) in enumerate(train_dataset.take(16)):\n","  ax = plt.subplot(4, 4, i + 1)\n","  \n","  plt.imshow(image)\n","  plt.title(dataset_info.features['label'].int2str(label))\n","  plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8btu7qeen1hX"},"outputs":[],"source":["# for i, (image, label) in enumerate(train_dataset.take(2)):\n","#   plt.subplot(1, 4, 2*i + 1)\n","#   plt.imshow(image)\n","\n","#   plt.subplot(1, 4, 2*i + 2)\n","#   plt.imshow(tf.image.adjust_saturation(image, 0.3))\n","\n","\n","#   plt.title(dataset_info.features['label'].int2str(label))\n","#   plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NT8DiQxbVMz7"},"outputs":[],"source":["dataset_info.features['label'].int2str(1)"]},{"cell_type":"markdown","metadata":{"id":"82Gqdfs9kjv3"},"source":["## Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"3BUZMRuhV-HL"},"source":["### Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKFOnzZQ7Fya"},"outputs":[],"source":["def visualize(original, augmented):\n","  plt.subplot(1,2,1)\n","  plt.imshow(original)\n","\n","  plt.subplot(1,2,2)\n","  plt.imshow(augmented)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMWtOY6e7OH-"},"outputs":[],"source":["original_image, label = next(iter(train_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aKifNjs7OSe"},"outputs":[],"source":["augmented_image = tf.image.adjust_saturation(original_image, saturation_factor = 0.3)#central_crop(original_image, 0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uo80zT197OT-"},"outputs":[],"source":["visualize(original_image, augmented_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rIXxlS6LVKmU"},"outputs":[],"source":["IM_SIZE = 224"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BKlhCPaR61p"},"outputs":[],"source":["original_image, label = next(iter(train_dataset))\n","@tf.function\n","def resize_rescale(image, label):\n","  #print(\"I was here\")\n","  #tf.print(\"I was here\")\n","  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0, label\n","\n","_, _ = resize_rescale(original_image, label)\n","_, _ = resize_rescale(original_image, label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7_OVJEtZQWV"},"outputs":[],"source":["#tf.config.run_functions_eagerly(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9dyO-k9mMYTc"},"outputs":[],"source":["### tf.keras.layer resizing and rescaling\n","resize_rescale_layers = tf.keras.Sequential([\n","       Resizing(IM_SIZE, IM_SIZE),\n","       Rescaling(1./255),                               \n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBXnNGAcVgXa"},"outputs":[],"source":["### tf.image augment\n","@tf.function\n","def augment(image, label):\n","  image, label = resize_rescale(image, label)\n","\n","  image = tf.image.rot90(image)\n","  #image = tf.image.adjust_saturation(image, saturation_factor = 0.3)\n","  image = tf.image.flip_left_right(image)\n","\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ck5ElZT53qd"},"outputs":[],"source":["class RotNinety(Layer):\n","  def __init__(self):\n","    super().__init__()\n","    \n","  @tf.function\n","  def call(self, image):\n","    return tf.image.rot90(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ii6zZKmX9cur"},"outputs":[],"source":["### tf.keras.layer augment\n","augment_layers = tf.keras.Sequential([\n","       RandomRotation(factor = (0.25, 0.2501),),\n","       RandomFlip(mode='horizontal',),\n","       RandomContrast(factor=0.1),\n","                                  \n","])\n","\n","@tf.function\n","def augment_layer(image, label):\n","  return augment_layers(resize_rescale_layers(image), training = True), label"]},{"cell_type":"markdown","metadata":{"id":"z_RZU3vxG2Aj"},"source":["### Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LaDqyvwZ7D6a"},"outputs":[],"source":["BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLkx-Ct8m8Ak"},"outputs":[],"source":["test_dataset = test_dataset.map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n","#train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5XbLitL4m9DA"},"outputs":[],"source":["# for image,label in train_dataset.take(1):\n","#   print(image, label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5ydz6dhm9Fc"},"outputs":[],"source":["\n","train_dataset = (\n","    train_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .map(augment_layer, num_parallel_calls = tf.data.AUTOTUNE)\n","    .batch(BATCH_SIZE)\n","    .prefetch(tf.data.AUTOTUNE)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cF4UBrf5eNmQ"},"outputs":[],"source":["val_dataset = (\n","    val_dataset\n","    .shuffle(buffer_size = 32)\n","    .map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n","    .batch(BATCH_SIZE)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OOK_U7-neNuy"},"outputs":[],"source":["val_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDlvxwC1m9Hl"},"outputs":[],"source":["train_dataset"]},{"cell_type":"markdown","metadata":{"id":"im-Eo6tvHgmM"},"source":["### MIxup Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PI_b_cBzJeRv"},"outputs":[],"source":["train_dataset_1 = train_dataset.shuffle(buffer_size = 4096, ).map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n","train_dataset_2 = train_dataset.shuffle(buffer_size = 4096, ).map(resize_rescale, num_parallel_calls = tf.data.AUTOTUNE)\n","\n","mixed_dataset = tf.data.Dataset.zip((train_dataset_1, train_dataset_2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Kaku3IHHkVN"},"outputs":[],"source":["def mixup(train_dataset_1, train_dataset_2):\n","  (image_1,label_1), (image_2, label_2) = train_dataset_1, train_dataset_2\n","\n","  lamda = tfp.distributions.Beta(0.2,0.2)\n","  lamda = lamda.sample(1)[0]\n","  \n","  image = lamda*image_1 + (1-lamda)*image_2\n","  label = lamda*tf.cast(label_1, dtype = tf.float32) + (1-lamda)*tf.cast(label_2, dtype = tf.float32)\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Uwj65QhL5ST"},"outputs":[],"source":["BATCH_SIZE = 32\n","train_dataset = (\n","    mixed_dataset\n","    .shuffle(buffer_size = 4096, reshuffle_each_iteration = True)\n","    .map(mixup, num_parallel_calls = tf.data.AUTOTUNE)\n","    #map(cutmix, num_parallel_calls = tf.data.AUTOTUNE)\n","    .batch(BATCH_SIZE)\n","    .prefetch(tf.data.AUTOTUNE)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKYfVCHsMV41"},"outputs":[],"source":["train_dataset"]},{"cell_type":"markdown","metadata":{"id":"IylKvmx5LUCR"},"source":["### CutMix Data *Augmentation*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4mfRVpjVKkz"},"outputs":[],"source":["def box(lamda):\n","  \n","  r_x = tf.cast(tfp.distributions.Uniform(0, IM_SIZE).sample(1)[0], dtype = tf.int32)\n","  r_y = tf.cast(tfp.distributions.Uniform(0, IM_SIZE).sample(1)[0], dtype = tf.int32)\n","\n","  r_w = tf.cast(IM_SIZE*tf.math.sqrt(1-lamda), dtype = tf.int32)\n","  r_h = tf.cast(IM_SIZE*tf.math.sqrt(1-lamda), dtype = tf.int32)\n","\n","  r_x = tf.clip_by_value(r_x - r_w//2, 0, IM_SIZE)\n","  r_y = tf.clip_by_value(r_y - r_h//2, 0, IM_SIZE)\n","\n","  x_b_r = tf.clip_by_value(r_x + r_w//2, 0, IM_SIZE)\n","  y_b_r = tf.clip_by_value(r_y + r_h//2, 0, IM_SIZE)\n","\n","  r_w = x_b_r - r_x\n","  if(r_w == 0):\n","    r_w  = 1\n","\n","  r_h = y_b_r - r_y\n","  if(r_h == 0):\n","    r_h = 1\n","\n","  return r_y, r_x, r_h, r_w"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QDH9vwpMLWBd"},"outputs":[],"source":["def cutmix(train_dataset_1, train_dataset_2):\n","  (image_1,label_1), (image_2, label_2) = train_dataset_1, train_dataset_2\n","\n","  lamda = tfp.distributions.Beta(0.2,0.2)\n","  lamda = lamda.sample(1)[0]\n","  \n","  r_y, r_x, r_h, r_w = box(lamda)\n","  crop_2 = tf.image.crop_to_bounding_box(image_2, r_y, r_x, r_h, r_w)\n","  pad_2 = tf.image.pad_to_bounding_box(crop_2, r_y, r_x, IM_SIZE, IM_SIZE)\n","\n","  crop_1 = tf.image.crop_to_bounding_box(image_1, r_y, r_x, r_h, r_w)\n","  pad_1 = tf.image.pad_to_bounding_box(crop_1, r_y, r_x, IM_SIZE, IM_SIZE)\n","\n","  image = image_1 - pad_1 + pad_2\n","\n","  lamda = tf.cast(1- (r_w*r_h)/(IM_SIZE*IM_SIZE), dtype = tf.float32)\n","  label = lamda*tf.cast(label_1, dtype = tf.float32) + (1-lamda)*tf.cast(label_2, dtype = tf.float32)\n","\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOKOaUrPwydO"},"outputs":[],"source":["original_image, label = next(iter(train_dataset))\n","print(label)\n","plt.imshow(original_image[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_SDW1m61zA3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PTW0fKw313gt"},"source":["### Albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFgRO86M87ME"},"outputs":[],"source":["!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWO057_PshWr"},"outputs":[],"source":["transforms = A.Compose(\n","    [\n","      A.Resize(IM_SIZE, IM_SIZE),\n","\n","      A.OneOf([A.HorizontalFlip(),\n","                A.VerticalFlip(),], p = 0.3),\n","      \n","      A.RandomRotate90(),   \n","      #A.RandomGridShuffle(grid=(3, 3), always_apply=False, p=0.5),\n","      A.RandomBrightnessContrast(brightness_limit=0.2,\n","                                contrast_limit=0.2,\n","                                always_apply=False, p=0.5),\n","      #A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, always_apply=False, p=0.5),\n","      A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), always_apply=False, p=0.5),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rlv9wdoRshZq"},"outputs":[],"source":["def aug_albument(image):\n","  data = {\"image\":image}\n","  image = transforms(**data)\n","  image = image[\"image\"]\n","  image = tf.cast(image/255., tf.float32)\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99IrNqzqEx9R"},"outputs":[],"source":["def process_data(image, label):\n","    aug_img = tf.numpy_function(func=aug_albument, inp=[image], Tout=tf.float32)\n","    return aug_img, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XR1XQju8ELjx"},"outputs":[],"source":["train_dataset = (\n","    train_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .map(process_data)\n","    .batch(BATCH_SIZE)\n","    .prefetch(tf.data.AUTOTUNE)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyDZGZWPELm3"},"outputs":[],"source":["train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAh74s-oELp_"},"outputs":[],"source":["im, _ = next(iter(train_dataset))\n","plt.imshow(im[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAC1aaCGELuJ"},"outputs":[],"source":["plt.figure(figsize=(15,15))\n","\n","for i in range(1,32):\n","  plt.subplot(8,4,i)\n","  plt.imshow(im[i])"]},{"cell_type":"markdown","metadata":{"id":"TeVM_g7JsaQr"},"source":["### Repeating the dataset (x5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mP8axz4dzc3d"},"outputs":[],"source":["def augment_1(image, label):\n","  image, label = resize_rescale(image, label)\n","\n","  image = tf.image.random_brightness(image, 0.2)\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QZE2UFX9zgI5"},"outputs":[],"source":["def augment_2(image, label):\n","  image, label = resize_rescale(image, label)\n","\n","  image = tf.image.random_flip_up_down(image)\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMnehRtxzmRA"},"outputs":[],"source":["def augment_3(image, label):\n","  image, label = resize_rescale(image, label)\n","\n","  image = tf.image.flip_left_right(image)\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Cq-vZyzzr1K"},"outputs":[],"source":["def augment_4(image, label):\n","  image, label = resize_rescale(image, label)\n","\n","  image = tf.image.rot90(image)\n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xz176pKqEp0c"},"outputs":[],"source":["def augment_5(image, label):\n","  image, label = resize_rescale(image, label)\n","  \n","  return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LidXL2P7tuAt"},"outputs":[],"source":["train_dataset_1 = (\n","    train_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .map(augment_1)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBFQt8Q58QCU"},"outputs":[],"source":["train_dataset_2 = (\n","    train_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .map(augment_2)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsTYAvRTEwvr"},"outputs":[],"source":["train_dataset_3 = (\n","    train_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .map(augment_3)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0kUetjtmEw25"},"outputs":[],"source":["train_dataset_4 = (\n","    train_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .map(augment_4)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2LrVC7SEw7f"},"outputs":[],"source":["train_dataset_5 = (\n","    train_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .map(augment_5)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yT3s-zBuS5l"},"outputs":[],"source":["full_dataset = train_dataset_1.concatenate(train_dataset_2).concatenate(train_dataset_3).concatenate(train_dataset_4).concatenate(train_dataset_5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZti4FnyzTce"},"outputs":[],"source":["full_dataset = (\n","    full_dataset\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .batch(BATCH_SIZE)\n","    .prefetch(tf.data.AUTOTUNE)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LdIY_Vgv0DLt"},"outputs":[],"source":["full_dataset"]},{"cell_type":"markdown","metadata":{"id":"Tn6iFj4SX3Sd"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSX0Fu-vYFAk"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"YM5OVNH9bHaW"},"source":["## WandB Dataset Versioning"]},{"cell_type":"markdown","metadata":{"id":"AsB9YnCuPITj"},"source":["### Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXo1OjaOPMNj"},"outputs":[],"source":["dataset, dataset_info = tfds.load('malaria', with_info=True, as_supervised=True, shuffle_files = True, split=['train'])\n","\n","print(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQCKKSWI6HX5"},"outputs":[],"source":["k = 0\n","for data in dataset[0]:\n","  \n","  with open('dataset/malaria_dataset_'+str(k) + '.npz', mode = 'wb') as file:\n","      np.savez(file, data)\n","  k += 1\n","  if(k%1000 == 0):\n","    print(k)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpFw5pGy57Tj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWKy1DX9b5Sm"},"outputs":[],"source":["def load_original_data():\n","  with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","    \n","    original_data = wandb.Artifact(\n","        name = \"new_dataset\", \n","        type=\"raw_data\",\n","        description = \"The Malaria dataset contains a total of 27,558 cell images with equal instances of parasitized and uninfected cells from the thin blood smear slide images of segmented cells.\",\n","        metadata = {\"source\": \"TFDS\",\n","                    \"homepage\": \"https://lhncbc.nlm.nih.gov/publication/pub9932\",\n","                    \"source_code\": \"tfds.image_classification.Malaria\",\n","                    \"version\": \"1.0.0\",\n","                    \"download_size\": \"337.08 MiB\",\n","                    }\n","    )\n","    \n","    original_data.add_dir('dataset/')\n","\n","    run.log_artifact(original_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0k4w6y8-uKAL"},"outputs":[],"source":["load_original_data()"]},{"cell_type":"markdown","metadata":{"id":"peB3_ExnPQl0"},"source":["### Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TrsaL8Ew-ctL"},"outputs":[],"source":["with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:    \n","  artifact = run.use_artifact('neuralearn/Malaria-Detection/new_dataset:v1', type='raw_data')\n","  artifact_dir = artifact.download()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oTgqIEHK-c1d"},"outputs":[],"source":["IM_SIZE = 224\n","def resize_rescale(image):\n","  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-2IapMA-c6c"},"outputs":[],"source":["def preprocess_data():\n","  with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","\n","    artifact = run.use_artifact('neuralearn/Malaria-Detection/new_dataset:v1', type='raw_data')\n","    artifact_dir = artifact.download()\n","\n","    preprocessed_data = wandb.Artifact(\n","        name = \"preprocessed_dataset\", \n","        type=\"preprocessed_data\",\n","        description = \"A Preprocessed version of the Malaria dataset\",\n","        \n","    )\n","\n","    artifact_directory = \"artifacts/new_dataset:v1/\"\n","\n","    dataset_x = []\n","    dataset_y = []\n","    \n","    for f in os.listdir(artifact_directory)[:1000]:\n","      with open(artifact_directory + f, 'rb') as file:\n","        npz_array = np.load(file, allow_pickle = True)\n","        \n","        x,y = npz_array.f.arr_0\n","\n","        dataset_x.append(resize_rescale(x))\n","        dataset_y.append(y)\n","    \n","    #dataset = tf.data.Dataset.from_tensor_slices((dataset_x, dataset_y))\n","\n","    with preprocessed_data.new_file(\"prep_dataset.npz\", mode = \"wb\") as file:\n","        np.savez(file, [dataset_x, dataset_y])\n","    run.log_artifact(preprocessed_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-qBgAOMmFk8"},"outputs":[],"source":["preprocess_data()"]},{"cell_type":"markdown","metadata":{"id":"hNqYhbE3pCzJ"},"source":["### Data Splitting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFTaqcEjuGkG"},"outputs":[],"source":["run = wandb.init()\n","artifact = run.use_artifact('neuralearn/Malaria-Detection/preprocessed_dataset:v2', type='preprocessed_data')\n","artifact_dir = artifact.download()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBq_XWI5uGp3"},"outputs":[],"source":["def split_data():\n","  with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","\n","    artifact = run.use_artifact('neuralearn/Malaria-Detection/preprocessed_dataset:v2', type='preprocessed_data')\n","    artifact_dir = artifact.download()\n","\n","    train_data = wandb.Artifact(\n","        name = \"train_dataset\", \n","        type=\"preprocessed_data\",\n","        description = \"Training dataset\",\n","        \n","    )\n","    val_data = wandb.Artifact(\n","        \n","        name = \"val_dataset\", \n","        type=\"preprocessed_data\",\n","        description = \"Validation dataset\",\n","            \n","        )\n","    test_data = wandb.Artifact(\n","        name = \"test_dataset\", \n","        type=\"preprocessed_data\",\n","        description = \"Test dataset\",\n","            \n","        )\n","    \n","    artifact_file = \"artifacts/preprocessed_dataset:v2/prep_dataset.npz\"\n","\n","    with open(artifact_file, 'rb') as file:\n","      npz_arr = np.load(file, allow_pickle = True)\n","      arr = npz_arr.f.arr_0\n","\n","    train_split = 0.8\n","    val_split = 0.1\n","    test_split = 0.1\n","    \n","    data_len = len(arr[0])\n","\n","    train_arr = [arr[0][0:int(train_split*data_len)], arr[1][0:int(train_split*data_len)]]\n","    val_arr = [arr[0][int(train_split*data_len):int((train_split+val_split)*data_len)], arr[1][int(train_split*data_len):int((train_split+val_split)*data_len)] ]\n","    test_arr = [arr[0][int((train_split+val_split)*data_len):], arr[1][int((train_split+val_split)*data_len):] ]\n","    \n","      \n","    with train_data.new_file(\"train_dataset.npz\", mode = \"wb\") as file:\n","        np.savez(file, train_arr)\n","        \n","    with val_data.new_file(\"val_dataset.npz\", mode = \"wb\") as file:\n","        np.savez(file, val_arr)\n","        \n","    with test_data.new_file(\"test_dataset.npz\", mode = \"wb\") as file:\n","        np.savez(file, test_arr)\n","        \n","\n","    run.log_artifact(train_data)  \n","    run.log_artifact(val_data)      \n","    run.log_artifact(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j8JbsekwuT3X"},"outputs":[],"source":["split_data()"]},{"cell_type":"markdown","metadata":{"id":"jYBajAUcpH9q"},"source":["### Data augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlyK2BQZpKE4"},"outputs":[],"source":["### tf.image augment\n","def augment(image):\n","  image = tf.image.rot90(image)\n","  image = tf.image.flip_left_right(image)\n","\n","  return image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llwsknTp7LYb"},"outputs":[],"source":["/contertifant/acts/train_dataset:v0/train_dataset.npz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l45yjHt27vkD"},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qO5J39tfFeef"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ee5e2tQw7vmk"},"outputs":[],"source":["def augment_data():\n","  with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","\n","    artifact = run.use_artifact('neuralearn/Malaria-Detection/train_dataset:v0', type='preprocessed_data')\n","    artifact_dir = artifact.download()\n","\n","    augmented_data = wandb.Artifact(\n","        name = \"Augmented_dataset\", \n","        type=\"preprocessed_data\",\n","        description = \"An Augmented version of the Malaria train dataset\",\n","    )\n","\n","    artifact_file = \"artifacts/train_dataset:v0/train_dataset.npz\"\n","    \n","    dataset_x = []\n","\n","    with open(artifact_file, 'rb') as file:\n","        npz_array = np.load(file, allow_pickle = True)\n","        \n","        arr = npz_array.f.arr_0\n","\n","        for im in arr[0]:\n","          dataset_x.append(augment(im))\n","        dataset_y = arr[1]\n","\n","    with augmented_data.new_file(\"aug_dataset.npz\", mode = \"wb\") as file:\n","        np.savez(file, [dataset_x, dataset_y])\n","    run.log_artifact(augmented_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7t7hU_qh_Wgs"},"outputs":[],"source":["augment_data()"]},{"cell_type":"markdown","metadata":{"id":"FUQgOMJGIZcU"},"source":["# Model Creation and Training"]},{"cell_type":"markdown","metadata":{"id":"iYaYGqawya5T"},"source":["## Wandb Model Versioning"]},{"cell_type":"markdown","metadata":{"id":"SRS_ONJC_dy9"},"source":["### Untrained Model Versioning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JH9h6T0XyfDi"},"outputs":[],"source":["def log_model():\n","  with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","\n","    \n","    untrained_model = wandb.Artifact(\n","        name = \"Untrained_model\", \n","        type=\"model\",\n","        description = \"The initial version of our lenet model\",\n","        metadata = CONFIGURATION\n","    )\n","    filename = 'lenet.h5'\n","    lenet_model.save(filename)\n","\n","    untrained_model.add_file(filename)\n","    wandb.save(filename)\n","    run.log_artifact(untrained_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSGomNAD60oM"},"outputs":[],"source":["log_model()"]},{"cell_type":"markdown","metadata":{"id":"L5HIIvUC_hsN"},"source":["### Trained Model versioning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpI1hw4i_jts"},"outputs":[],"source":["def train_and_log():\n","  with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","\n","    artifact = run.use_artifact('neuralearn/Malaria-Detection/Augmented_dataset:v0', type='preprocessed_data')\n","    artifact_dir = artifact.download()\n","\n","    trained_sequential_model = wandb.Artifact(\n","        name = \"Trained_Sequential_model\", \n","        type=\"model\",\n","        description = \"A trained version of our model\",\n","        metadata = CONFIGURATION,\n","    )\n","\n","    artifact_file = \"artifacts/Augmented_dataset:v0/aug_dataset.npz\"\n","        \n","    dataset_x = []\n","\n","    with open(artifact_file, 'rb') as file:\n","        npz_array = np.load(file, allow_pickle = True)\n","        \n","        arr = npz_array.f.arr_0\n","\n","        for im in arr[0]:\n","          dataset_x.append(im)\n","        dataset_y = arr[1]\n","    \n","\n","    d_x = tf.convert_to_tensor(dataset_x, dtype = tf.float32)\n","    d_y = tf.convert_to_tensor(dataset_y, dtype = tf.float32)\n","\n","    d = tf.data.Dataset.from_tensor_slices((d_x,d_y))\n","\n","    train_d = (\n","        d\n","        .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","        .batch(BATCH_SIZE)\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","\n","\n","    artifact = run.use_artifact('neuralearn/Malaria-Detection/Untrained_model:v0', type='model')\n","    artifact_dir = artifact.download()\n","\n","    artifact_file = \"artifacts/Untrained_model:v0/lenet.h5\"\n","\n","    lenet_model = tf.keras.models.load_model(artifact_file)\n","\n","    metrics = [TruePositives(name='tp'),FalsePositives(name='fp'), TrueNegatives(name='tn'), FalseNegatives(name='fn'), \n","                BinaryAccuracy(name='accuracy'), Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n","\n","    lenet_model.compile(optimizer = Adam(learning_rate = CONFIGURATION['LEARNING_RATE']),\n","          loss = BinaryCrossentropy(),\n","          metrics = metrics)\n","\n","    lenet_model.fit(\n","        train_d,\n","        epochs = 3,\n","        verbose = 1,\n","        callbacks=[WandbCallback()],\n","    )\n","    \n","    filename = 'lenet_trained.h5'\n","    lenet_model.save(filename)\n","\n","    trained_sequential_model.add_file(filename)\n","    wandb.save(filename)\n","    run.log_artifact(trained_sequential_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DywVLvth_jyL"},"outputs":[],"source":["train_and_log()"]},{"cell_type":"markdown","metadata":{"id":"lcZooLJ_fLsm"},"source":["## Sequential API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QwVD7qdm9KK"},"outputs":[],"source":["IM_SIZE = CONFIGURATION['IM_SIZE']\n","DROPOUT_RATE = CONFIGURATION['DROPOUT_RATE']\n","REGULARIZATION_RATE = CONFIGURATION['REGULARIZATION_RATE']\n","N_FILTERS = CONFIGURATION['N_FILTERS']\n","KERNEL_SIZE = CONFIGURATION['KERNEL_SIZE']\n","POOL_SIZE = CONFIGURATION['POOL_SIZE']\n","N_STRIDES = CONFIGURATION['N_STRIDES']\n","\n","lenet_model = tf.keras.Sequential([\n","    InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n","\n","    Conv2D(filters = N_FILTERS , kernel_size = KERNEL_SIZE, strides = N_STRIDES , padding='valid',\n","          activation = 'relu',kernel_regularizer = L2(REGULARIZATION_RATE)),\n","    BatchNormalization(),\n","    MaxPool2D (pool_size = POOL_SIZE, strides= N_STRIDES*2),\n","    Dropout(rate = DROPOUT_RATE ),\n","\n","    Conv2D(filters = N_FILTERS*2 + 4, kernel_size = KERNEL_SIZE, strides=N_STRIDES, padding='valid',\n","          activation = 'relu', kernel_regularizer = L2(REGULARIZATION_RATE)),\n","    BatchNormalization(),\n","    MaxPool2D (pool_size = POOL_SIZE, strides= N_STRIDES*2),\n","\n","    Flatten(),\n","    \n","    Dense( CONFIGURATION['N_DENSE_1'], activation = \"relu\", kernel_regularizer = L2(REGULARIZATION_RATE)),\n","    BatchNormalization(),\n","    Dropout(rate = DROPOUT_RATE),\n","    \n","    Dense( CONFIGURATION['N_DENSE_2'], activation = \"relu\", kernel_regularizer = L2(REGULARIZATION_RATE)),\n","    BatchNormalization(),\n","\n","    Dense(1, activation = \"sigmoid\"),\n","\n","])\n","\n","lenet_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-snscgqO4u36"},"outputs":[],"source":["def train_and_log():\n","  with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","\n","    artifact = run.use_artifact('neuralearn/Malaria-Detection/Augmented_dataset:v0', type='preprocessed_data')\n","    artifact_dir = artifact.download()\n","\n","    sequential_model = wandb.Artifact(\n","        name = \"Sequential_model\", \n","        type=\"model\",\n","        description = \"A trained version of our model\",\n","        \n","    )\n","\n","    artifact_file = \"artifacts/train_dataset:v0/aug_dataset.npz\"\n","    \n","    dataset_x = []\n","\n","    with open(artifact_file, 'rb') as file:\n","        npz_array = np.load(file, allow_pickle = True)\n","        \n","        arr = npz_array.f.arr_0\n","\n","        for im in arr[0]:\n","          dataset_x.append(augment(im))\n","        dataset_y = arr[1]\n","\n","        # metrics = [TruePositives(name='tp'),FalsePositives(name='fp'), TrueNegatives(name='tn'), FalseNegatives(name='fn'), \n","        #             BinaryAccuracy(name='accuracy'), Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n","        # FACTOR = 1\n","        # LABELS = ['Parasitized', 'Uninfected']\n","\n","\n","        # lenet_model.compile(optimizer = Adam(learning_rate = CONFIGURATION['LEARNING_RATE']),\n","        #       loss = BinaryCrossentropy(),\n","        #       metrics = metrics)\n","\n","        # history = lenet_model.fit(\n","        #     train_dataset,\n","        #     validation_data = val_dataset,\n","        #     epochs = 23,#CONFIGURATION['N_EPOCHS'],\n","        #     verbose = 1,\n","        #     #callbacks=[LogImagesCallbackWandB()]\n","        #     )\n","\n","    # with preprocessed_data.new_file(\"aug_dataset.npz\", mode = \"wb\") as file:\n","    #     np.savez(file, [dataset_x, dataset_y])\n","\n","    # run.log_artifact(preprocessed_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fc6sCUD84u6I"},"outputs":[],"source":["train_and_log()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAoTZNps4u8r"},"outputs":[],"source":["artifact_file = \"artifacts/Augmented_dataset:v0/aug_dataset.npz\"\n","    \n","dataset_x = []\n","\n","with open(artifact_file, 'rb') as file:\n","    npz_array = np.load(file, allow_pickle = True)\n","    \n","    arr = npz_array.f.arr_0\n","\n","    for im in arr[0]:\n","      dataset_x.append(im)\n","    dataset_y = arr[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRbHFk7m7fdi"},"outputs":[],"source":["print(dataset_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vyPzaNb8xQF"},"outputs":[],"source":["d_x = tf.convert_to_tensor(dataset_x, dtype = tf.float32)\n","d_y = tf.convert_to_tensor(dataset_y, dtype = tf.float32)\n","\n","print(d_x.shape, d_y.shape)\n","\n","d = tf.data.Dataset.from_tensor_slices((d_x,d_y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-hCCnHS_pOX"},"outputs":[],"source":["for i in d.take(2):\n","  print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWgnfnR2DRzO"},"outputs":[],"source":["BATCH_SIZE = 32\n","\n","train_d = (\n","    d\n","    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n","    .batch(BATCH_SIZE)\n","    .prefetch(tf.data.AUTOTUNE)\n",")\n","print(train_d)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9GbecTJ47uyr"},"outputs":[],"source":["metrics = [TruePositives(name='tp'),FalsePositives(name='fp'), TrueNegatives(name='tn'), FalseNegatives(name='fn'), \n","            BinaryAccuracy(name='accuracy'), Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n","FACTOR = 1\n","LABELS = ['Parasitized', 'Uninfected']\n","\n","\n","lenet_model.compile(optimizer = Adam(learning_rate = CONFIGURATION['LEARNING_RATE']),\n","      loss = BinaryCrossentropy(),\n","      metrics = metrics)\n","\n","history = lenet_model.fit(\n","    train_d,\n","    #validation_data = val_dataset,\n","    epochs = 2,#CONFIGURATION['N_EPOCHS'],\n","    verbose = 1,\n","    #callbacks=[LogImagesCallbackWandB()]\n","    )"]},{"cell_type":"markdown","metadata":{"id":"kbm2WoMpfXod"},"source":["## Functional API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NeMyO6e1C4u7"},"outputs":[],"source":["func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input Image\")\n","\n","x = Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation = 'relu')(func_input)\n","x = BatchNormalization()(x)\n","x = MaxPool2D (pool_size = 2, strides= 2)(x)\n","\n","x = Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation = 'relu')(x)\n","x = BatchNormalization()(x)\n","output = MaxPool2D (pool_size = 2, strides= 2)(x)\n","\n","feature_extractor_model = Model(func_input, output, name = \"Feature_Extractor\")\n","feature_extractor_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMYcqj4Kdnpt"},"outputs":[],"source":["feature_extractor_seq_model = tf.keras.Sequential([\n","                             InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n","\n","                             Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),\n","                             BatchNormalization(),\n","                             MaxPool2D (pool_size = 2, strides= 2),\n","\n","                             Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),\n","                             BatchNormalization(),\n","                             MaxPool2D (pool_size = 2, strides= 2),\n","\n","                             \n","\n","])\n","feature_extractor_seq_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"11Wz41MHkzTu"},"source":["## Callable Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zrkk0npZfYBJ"},"outputs":[],"source":["func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input Image\")\n","\n","x = feature_extractor_seq_model(func_input)\n","\n","x = Flatten()(x)\n","\n","x = Dense(100, activation = \"relu\")(x)\n","x = BatchNormalization()(x)\n","\n","x = Dense(10, activation = \"relu\")(x)\n","x = BatchNormalization()(x)\n","\n","func_output = Dense(1, activation = \"sigmoid\")(x)\n","\n","lenet_model_func = Model(func_input, func_output, name = \"Lenet_Model\")\n","lenet_model_func.summary()"]},{"cell_type":"markdown","metadata":{"id":"3arkQ973eIjM"},"source":["## Model Subclassing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4JaTaX9lEPK"},"outputs":[],"source":["class FeatureExtractor(Layer):\n","  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size,):\n","    super(FeatureExtractor, self).__init__()\n","\n","    self.conv_1 = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)\n","    self.batch_1 = BatchNormalization()\n","    self.pool_1 = MaxPool2D (pool_size = pool_size, strides= 2*strides)\n","\n","    self.conv_2 = Conv2D(filters = filters*2, kernel_size = kernel_size, strides = strides, padding = padding, activation = activation)\n","    self.batch_2 = BatchNormalization()\n","    self.pool_2 = MaxPool2D (pool_size = pool_size, strides= 2*strides)\n","\n","  def call(self, x, training):\n","\n","    x = self.conv_1(x)\n","    x = self.batch_1(x)\n","    x = self.pool_1(x)\n","\n","    x = self.conv_2(x)\n","    x = self.batch_2(x)\n","    x = self.pool_2(x)\n","\n","    return x\n","feature_sub_classed = FeatureExtractor(8, 3, 1, \"valid\", \"relu\", 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDPkCi9ZhQ70"},"outputs":[],"source":["func_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input Image\")\n","\n","x = feature_sub_classed(func_input)\n","\n","x = Flatten()(x)\n","\n","x = Dense(100, activation = \"relu\")(x)\n","x = BatchNormalization()(x)\n","\n","x = Dense(10, activation = \"relu\")(x)\n","x = BatchNormalization()(x)\n","\n","func_output = Dense(1, activation = \"sigmoid\")(x)\n","\n","lenet_model_func = Model(func_input, func_output, name = \"Lenet_Model\")\n","lenet_model_func.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8E1KU0QndJX"},"outputs":[],"source":["class LenetModel(Model):\n","  def __init__(self):\n","    super(LenetModel, self).__init__()\n","\n","    self.feature_extractor = FeatureExtractor(8, 3, 1, \"valid\", \"relu\", 2)\n","\n","    self.flatten = Flatten()\n","\n","    self.dense_1 = Dense(100, activation = \"relu\")\n","    self.batch_1 = BatchNormalization()\n","\n","    self.dense_2 = Dense(10, activation = \"relu\")\n","    self.batch_2 = BatchNormalization()\n","\n","    self.dense_3 = Dense(1, activation = \"sigmoid\")\n","    \n","  def call(self, x, training):\n","\n","    x = self.feature_extractor(x)\n","    x = self.flatten(x)\n","    x = self.dense_1(x)\n","    x = self.batch_1(x)\n","    x = self.dense_2(x)\n","    x = self.batch_2(x)\n","    x = self.dense_3(x)\n","\n","    return x\n","    \n","lenet_sub_classed = LenetModel()\n","lenet_sub_classed(tf.zeros([1,224,224,3]))\n","lenet_sub_classed.summary()"]},{"cell_type":"markdown","metadata":{"id":"xgF_fkT-qngT"},"source":["## Custom Layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKLHl1obqoVJ"},"outputs":[],"source":["class NeuralearnDense(Layer):\n","  def __init__(self, output_units, activation):\n","    super(NeuralearnDense, self).__init__()\n","    self.output_units = output_units\n","    self.activation = activation\n","  \n","  def build(self, input_features_shape):\n","    self.w = self.add_weight(shape = (input_features_shape[-1], self.output_units), initializer = \"random_normal\", trainable = True)\n","    self.b = self.add_weight(shape = (self.output_units,), initializer = \"random_normal\", trainable = True)\n","  \n","  def call(self, input_features):\n","\n","    pre_output = tf.matmul(input_features, self.w) + self.b\n","\n","    if(self.activation == \"relu\"):\n","      return tf.nn.relu(pre_output)\n","\n","    elif(self.activation == \"sigmoid\"):\n","      return tf.math.sigmoid(pre_output)\n","\n","    else:\n","      return pre_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jz30O0yV2rGk"},"outputs":[],"source":["IM_SIZE = 224\n","lenet_custom_model = tf.keras.Sequential([\n","                             InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n","\n","                             Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),\n","                             BatchNormalization(),\n","                             MaxPool2D (pool_size = 2, strides= 2),\n","\n","                             Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid', activation = 'relu'),\n","                             BatchNormalization(),\n","                             MaxPool2D (pool_size = 2, strides= 2),\n","\n","                             Flatten(),\n","                             \n","                             NeuralearnDense(100, activation = \"relu\"),\n","                             BatchNormalization(),\n","                             \n","                             NeuralearnDense(10, activation = \"relu\"),\n","                             BatchNormalization(),\n","\n","                             NeuralearnDense(1, activation = \"sigmoid\"),\n","\n","])\n","lenet_custom_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"20ultY2FdfyX"},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","## Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LG6nVKSXdfcu"},"outputs":[],"source":["class LossCallback(Callback):\n","  def on_epoch_end(self, epoch, logs):\n","    print(\"\\n For Epoch Number {} the model has a loss of {} \".format(epoch+1, logs[\"loss\"]))\n","    \n","  def on_batch_end(self, batch, logs):\n","    print(\"\\n For Batch Number {} the model has a loss of {} \".format(batch+1, logs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9PSIylC4dAI"},"outputs":[],"source":["test_dataset = test_dataset.batch(1)\n","\n","# images = wandb.Image(image_array, caption=\"Top: Output, Bottom: Input\")\n","\n","# wandb.log({\"examples\": images})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSzBOy-m4Fnh"},"outputs":[],"source":["class LogImagesCallbackTensorBoard(Callback):\n","  def on_epoch_end(self, epoch, logs):\n","    labels = []\n","    inp = []\n","\n","    for x,y in test_dataset.as_numpy_iterator():\n","      labels.append(y)\n","      inp.append(x)\n","    labels = np.array([i[0] for i in labels])\n","    predicted = lenet_model.predict(np.array(inp)[:,0,...])\n","\n","    threshold = 0.5\n","\n","    cm = confusion_matrix(labels, predicted > threshold)\n","    \n","    plt.figure(figsize=(8,8))\n","\n","    sns.heatmap(cm, annot=True,)\n","    plt.title('Confusion matrix - {}'.format(threshold))\n","    plt.ylabel('Actual')\n","    plt.xlabel('Predicted')\n","    plt.axis('off')\n","\n","    buffer = io.BytesIO()\n","    plt.savefig(buffer, format = 'png')\n","\n","    image = tf.image.decode_png(buffer.getvalue(), channels=3)\n","    image = tf.expand_dims(image, axis = 0)\n","\n","    CURRENT_TIME = datetime.datetime.now().strftime('%d%m%y - %h%m%s')\n","    IMAGE_DIR = './logs/' + CURRENT_TIME + '/images'\n","    image_writer = tf.summary.create_file_writer(IMAGE_DIR)\n","    \n","    with image_writer.as_default():\n","      tf.summary.image(\"Training data\", image, step = epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTbdFZ93Tnzr"},"outputs":[],"source":["class LogImagesCallbackWandBPlot(Callback):\n","  def on_epoch_end(self, epoch, logs):\n","    labels = []\n","    inp = []\n","\n","    for x,y in test_dataset.as_numpy_iterator():\n","      labels.append(y)\n","      inp.append(x)\n","    labels = np.array([i[0] for i in labels])\n","    predicted = lenet_model.predict(np.array(inp)[:,0,...])\n","\n","    print(\"labels\", labels, labels.dtype)\n","    print(\"predicted\", predicted, predicted.dtype)\n","\n","    pred = []\n","\n","    for i in range(len(predicted)):\n","      if(predicted[i][0] < 0.5):\n","        pred.append([1,0])\n","      else:\n","        pred.append([0,1])\n","\n","    pred = np.array(pred)\n","\n","    # wandb.log({\"Confusion Matrix\" : wandb.plot.confusion_matrix(\n","    #     probs = pred,\n","    #     y_true=labels,\n","    #     class_names=[\"Parasitized\", \"Uninfected\"])})\n","\n","    wandb.log({\"ROC Curve\" : wandb.plot.roc_curve(\n","        y_true = labels,\n","        y_probas = pred,\n","        labels = ['Parasitized', 'Uninfected'], \n","    )})\n","\n","    wandb.log({'loss':logs['loss']})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ng6lfPud-i7v"},"outputs":[],"source":["class LogImagesCallbackWandB(Callback):\n","  def on_epoch_end(self, epoch, logs):\n","    labels = []\n","    inp = []\n","\n","    for x,y in test_dataset.as_numpy_iterator():\n","      labels.append(y)\n","      inp.append(x)\n","    labels = np.array([i[0] for i in labels])\n","    predicted = lenet_model.predict(np.array(inp)[:,0,...])\n","\n","    threshold = 0.5\n","\n","    cm = confusion_matrix(labels, predicted > threshold)\n","    \n","    plt.figure(figsize=(8,8))\n","\n","    sns.heatmap(cm, annot=True,)\n","    plt.title('Confusion matrix - {}'.format(threshold))\n","    plt.ylabel('Actual')\n","    plt.xlabel('Predicted')\n","    plt.axis('off')\n","\n","    buffer = io.BytesIO()\n","    plt.savefig(buffer, format = 'png')\n","\n","    image_array = tf.image.decode_png(buffer.getvalue(), channels=3)\n","\n","    images = wandb.Image(image_array, caption=\"Confusion Matrix for epoch: {}\".format(epoch))\n","          \n","    wandb.log(\n","        {\"Confusion Matrix\": images})\n","    "]},{"cell_type":"markdown","metadata":{"id":"413m-l0pttrt"},"source":["### CSVLogger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZKjzj32tsHN"},"outputs":[],"source":["csv_callback = CSVLogger(\n","    'logs.csv', separator=',', append=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"lLaHf-B12OH8"},"source":["### EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sr-2Nzup2OcU"},"outputs":[],"source":["es_callback = EarlyStopping(\n","    monitor='val_loss', min_delta=0, patience=2, verbose=1,\n","    mode='auto', baseline=None, restore_best_weights=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"P04zuKYv_hex"},"source":["### Tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKAAjue_KM8G"},"outputs":[],"source":["pip install -U tensorboard_plugin_profile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VhhaW037s-9V"},"outputs":[],"source":["!rm -rf ./logs/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"15BqZlHGKtW5"},"outputs":[],"source":["CURRENT_TIME = datetime.datetime.now().strftime('%d%m%y - %h%m%s')\n","METRIC_DIR = './logs/' + CURRENT_TIME + '/metrics'\n","train_writer = tf.summary.create_file_writer(METRIC_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CV7CC2YI_ht3"},"outputs":[],"source":["LOG_DIR = './logs/'+ CURRENT_TIME\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq = 1, profile_batch = '100,132')"]},{"cell_type":"markdown","metadata":{"id":"yvoXsM8zC6bD"},"source":["### LearningRateScheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_b3eU9yTC69J"},"outputs":[],"source":["def scheduler(epoch, lr):\n","\n","  if epoch <= 1:\n","    learning_rate = lr\n","  else:\n","    learning_rate = lr * tf.math.exp(-0.1)\n","    learning_rate = learning_rate.numpy()\n","\n","  with train_writer.as_default():\n","    tf.summary.scalar('Learning Rate', data = learning_rate, step = epoch)\n","  return learning_rate\n","scheduler_callback = LearningRateScheduler(scheduler, verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"ZEau-uvfRWA5"},"source":["### ModelCheckpointing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dBXgkarRZT6"},"outputs":[],"source":["checkpoint_callback = ModelCheckpoint(\n","    'weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_precision', verbose=0, save_best_only=True,\n","    save_weights_only=True, mode='auto', save_freq='epoch',\n",")"]},{"cell_type":"markdown","metadata":{"id":"-t5zQwWckCS9"},"source":["### ReduceLearningRateOnPlateau"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGkKibvGkC6A"},"outputs":[],"source":["plateau_callback = ReduceLROnPlateau(\n","    monitor='val_accuracy', factor=0.1, patience=5, verbose=1\n",")"]},{"cell_type":"markdown","metadata":{"id":"Rrm7NNzuDd5k"},"source":["## Custom Metric Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AhN8td6XDeLC"},"outputs":[],"source":["class CustomAccuracy(tf.keras.metrics.Metric):\n","  def __init__(self, name = 'Custom_Accuracy', FACTOR = 1):\n","    super(CustomAccuracy, self).__init__()\n","    self.FACTOR = FACTOR\n","    self.accuracy = self.add_weight(name = name, initializer = 'zeros')\n","\n","\n","  def update_state(self, y_true, y_pred, sample_weight = None):\n","    output = binary_accuracy(tf.cast(y_true, dtype = tf.float32), y_pred)*self.FACTOR\n","    self.accuracy.assign(tf.math.count_nonzero(output, dtype = tf.float32)/tf.cast(len(output), dtype = tf.float32))\n","\n","  def result(self):\n","    return self.accuracy\n","\n","  def reset_states(self):\n","    self.accuracy.assign(0.)"]},{"cell_type":"markdown","metadata":{"id":"_AcriqBA2IU4"},"source":["## Custom Metric Method (without parametres)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7JvNwoUw2IfR"},"outputs":[],"source":["def custom_accuracy(y_true, y_pred):\n","  print(binary_accuracy(y_true, y_pred))\n","  return binary_accuracy(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"2bEezFeL_8tr"},"source":["## Custom Metric Method (with Parametres)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TU1emg1I_9CB"},"outputs":[],"source":["def custom_accuracy(FACTOR):\n","  def metric(y_true, y_pred):\n","    return binary_accuracy(y_true, y_pred)* FACTOR\n","  return metric"]},{"cell_type":"markdown","metadata":{"id":"-0mircHogrvl"},"source":["## Custom Loss Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlzFZ7wzgyec"},"outputs":[],"source":["class CustomBCE(tf.keras.losses.Loss):\n","  def __init__(self, FACTOR):\n","    super(CustomBCE, self).__init__()\n","    self.FACTOR = FACTOR\n","  def call(self, y_true, y_pred):\n","    bce = BinaryCrossentropy()\n","    return bce(y_true, y_pred)* self.FACTOR"]},{"cell_type":"markdown","metadata":{"id":"JhawCc8jf8JB"},"source":["## Custom Loss Method (with parametres)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcmUelUKUShm"},"outputs":[],"source":["def custom_bce(FACTOR):\n","  def loss(y_true, y_pred):\n","    bce = BinaryCrossentropy()\n","    return bce(y_true, y_pred)* FACTOR\n","  return loss"]},{"cell_type":"markdown","metadata":{"id":"J3I7Zhyufjsf"},"source":["## Custom Loss Method (without parametres)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTNBj8yqfsq-"},"outputs":[],"source":["def custom_bce(y_true, y_pred):\n","  bce = BinaryCrossentropy()\n","  return bce(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"1AicRPfDS79d"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hV-cIEXu6aZo"},"outputs":[],"source":["metrics = [TruePositives(name='tp'),FalsePositives(name='fp'), TrueNegatives(name='tn'), FalseNegatives(name='fn'), \n","            BinaryAccuracy(name='accuracy'), Precision(name='precision'), Recall(name='recall'), AUC(name='auc')]\n","FACTOR = 1\n","LABELS = ['Parasitized', 'Uninfected']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXa7OBPBm9O2"},"outputs":[],"source":["lenet_model.compile(optimizer = Adam(learning_rate = CONFIGURATION['LEARNING_RATE']),\n","      loss = BinaryCrossentropy(),\n","      metrics = metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLWDksoJ0hU0"},"outputs":[],"source":["history = lenet_model.fit(\n","    train_dataset,\n","    validation_data = val_dataset,\n","    epochs = 23,#CONFIGURATION['N_EPOCHS'],\n","    verbose = 1,\n","    #callbacks=[LogImagesCallbackWandB()]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDlEZcNtAO2J"},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"DxMyYeM-DmlM"},"source":["## Hyperparameter Tuning with WandB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fU9usxE4UcEo"},"outputs":[],"source":["sweep_config = {\n","  \"name\" : \"Malaria-Prediction-Sweep\",\n","  \"method\" : \"random\",\n","  \"metric\": {\n","      \"name\" : \"accuracy\",\n","      \"goal\" : \"maximize\",\n","  },\n","  \"parameters\" : {\n","    \n","    \"IM_SIZE\": {\n","        \"value\" : 224,\n","    },\n","\n","    \"N_EPOCHS\": {\n","        \"value\" : 1,\n","    },\n","    \n","    \"KERNEL_SIZE\": {\n","        \"value\" : 3,\n","    },\n","\n","    \"N_STRIDES\": {\n","        \"value\" : 1,\n","    },\n","\n","    \"POOL_SIZE\": {\n","        \"value\" : 224,\n","    },\n","  \n","    \"N_FILTERS\" : {\n","        \"value\" : 6,\n","    },\n","      \n","    \"N_DENSE_1\" : {\n","      \"values\" : [16, 32, 64, 128]\n","    },\n","\n","    \"N_DENSE_2\" : {\n","      \"values\" : [16, 32, 64, 128]\n","    },\n","\n","    \"DROPOUT_RATE\":{\n","      \"min\": 0.1,\n","      \"max\": 0.4\n","    },\n","\n","    \"REGULARIZATION_RATE\" :{\n","      \"distribution\": \"uniform\",\n","      \"min\": 0.001,\n","      \"max\": 0.1\n","    },\n","\n","    \"LEARNING_RATE\" :{\n","      \"distribution\": \"uniform\",\n","      \"min\": 1e-4,\n","      \"max\": 1e-2\n","    }\n","  },\n","}\n","\n","sweep_id = wandb.sweep(sweep_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDI4jVQkMZpU"},"outputs":[],"source":["IM_SIZE = 224\n","def model_tune(config):\n","  lenet_model = tf.keras.Sequential([\n","    InputLayer(input_shape = (224, 224, 3)),\n","\n","    Conv2D(filters = 6 , kernel_size = 3, strides = 1 , padding='valid',\n","          activation = 'relu',kernel_regularizer = L2(config['REGULARIZATION_RATE'])),\n","    BatchNormalization(),\n","    MaxPool2D (pool_size = 1, strides= config['N_STRIDES']*2),\n","    Dropout(rate = config['DROPOUT_RATE'] ),\n","\n","    Conv2D(filters = 16, kernel_size = 3, strides = 1, padding='valid',\n","          activation = 'relu', kernel_regularizer = L2(config['REGULARIZATION_RATE'])),\n","    BatchNormalization(),\n","    MaxPool2D (pool_size = 1, strides= 2),\n","\n","    Flatten(),\n","    \n","    Dense( config['N_DENSE_1'], activation = \"relu\", kernel_regularizer = L2(config['REGULARIZATION_RATE'])),\n","    BatchNormalization(),\n","    Dropout(rate = DROPOUT_RATE),\n","    \n","    Dense( config['N_DENSE_2'], activation = \"relu\", kernel_regularizer = L2(config['REGULARIZATION_RATE'])),\n","    BatchNormalization(),\n","\n","    Dense(1, activation = \"sigmoid\"),\n","\n","  ])\n","\n","\n","  return lenet_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ayj_1UaJM9Nk"},"outputs":[],"source":["wandb.config = {\n","  \"LEARNING_RATE\": 0.001,\n","  \"N_EPOCHS\": 1,\n","  \"BATCH_SIZE\": 128,\n","  \"DROPOUT_RATE\": 0.0,\n","  \"IM_SIZE\": 224,\n","  \"REGULARIZATION_RATE\": 0.0,\n","  \"N_FILTERS\": 6,\n","  \"KERNEL_SIZE\": 3,\n","  \"N_STRIDES\": 1,\n","  \"POOL_SIZE\": 2,\n","  \"N_DENSE_1\": 100,\n","  \"N_DENSE_2\": 10,\n","}\n","CONFIGURATION = wandb.config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Xb32xrsDsOA"},"outputs":[],"source":["def train():\n","    with wandb.init(project=\"Malaria-Detection\", entity=\"neuralearn\") as run:\n","        config = wandb.config\n","        model = model_tune(config)\n","        model.compile(\n","              optimizer= Adam(\n","                  learning_rate = config['LEARNING_RATE']),\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'],\n","              )\n","        model.fit(val_dataset, epochs=2, callbacks = [WandbCallback()])\n","        #wandb.log({\"loss\": loss, \"epoch\": epoch})\n","\n","count = 5 # number of runs to execute\n","wandb.agent(sweep_id, function=train, count=count)"]},{"cell_type":"markdown","metadata":{"id":"zzS9pcnOPRva"},"source":["## Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GAUfFaBvPT7c"},"outputs":[],"source":["IM_SIZE = 224\n","def model_tune(hparams):\n","  lenet_model = tf.keras.Sequential([\n","    InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n","\n","    Conv2D(filters = 6, kernel_size = 3, strides=1, padding='valid',\n","          activation = 'relu',kernel_regularizer = L2(hparams[HP_REGULARIZATION_RATE])),\n","    BatchNormalization(),\n","    MaxPool2D (pool_size = 2, strides= 2),\n","    Dropout(rate = hparams[HP_DROPOUT]),\n","\n","    Conv2D(filters = 16, kernel_size = 3, strides=1, padding='valid',\n","          activation = 'relu', kernel_regularizer = L2(hparams[HP_REGULARIZATION_RATE])),\n","    BatchNormalization(),\n","    MaxPool2D (pool_size = 2, strides= 2),\n","\n","    Flatten(),\n","    \n","    Dense( hparams[HP_NUM_UNITS_1], activation = \"relu\", kernel_regularizer = L2(hparams[HP_REGULARIZATION_RATE])),\n","    BatchNormalization(),\n","    Dropout(rate = hparams[HP_DROPOUT]),\n","    \n","    Dense(hparams[HP_NUM_UNITS_2], activation = \"relu\", kernel_regularizer = L2(hparams[HP_REGULARIZATION_RATE])),\n","    BatchNormalization(),\n","\n","    Dense(1, activation = \"sigmoid\"),\n","  ])\n","\n","  lenet_model.compile(\n","        optimizer= Adam(learning_rate = hparams[HP_LEARNING_RATE]),\n","        loss='binary_crossentropy',\n","        metrics=['accuracy'],\n","    )\n","\n","  lenet_model.fit(val_dataset, epochs=1)\n","  _, accuracy = lenet_model.evaluate(val_dataset)\n","  return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fG9GX1iNdAfB"},"outputs":[],"source":["HP_NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([16,32,64,128]))\n","HP_NUM_UNITS_2 = hp.HParam('num_units_2', hp.Discrete([16,32,64,128]))\n","HP_DROPOUT = hp.HParam('dropout_rate', hp.Discrete([0.1,0.2,0.3]))\n","HP_REGULARIZATION_RATE = hp.HParam('regularization_rate', hp.Discrete([0.001,0.01,0.1]))\n","HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-4, 1e-3]))\n","\n","fixed range of values is very large\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TH58PrBWuE68"},"outputs":[],"source":["run_number = 0\n","for num_units_1 in HP_NUM_UNITS_1.domain.values:\n","  for num_units_2 in HP_NUM_UNITS_2.domain.values:\n","    for dropout_rate in HP_DROPOUT.domain.values:\n","      for regularization_rate in HP_REGULARIZATION_RATE.domain.values:\n","        for learning_rate in HP_LEARNING_RATE.domain.values:\n","\n","          hparams = {\n","              HP_NUM_UNITS_1: num_units_1,\n","              HP_NUM_UNITS_2: num_units_2,\n","              HP_DROPOUT: dropout_rate,\n","              HP_REGULARIZATION_RATE: regularization_rate,\n","              HP_LEARNING_RATE: learning_rate,\n","              \n","          }\n","          file_writer = tf.summary.create_file_writer('logs/hparams-' + str(run_number))\n","\n","          with file_writer.as_default():\n","              hp.hparams(hparams)\n","              accuracy = model_tune(hparams)\n","              tf.summary.scalar('accuracy', accuracy, step = 0)\n","          print(\"For the run {}, hparams num_units_1:{}, num_units_2:{}, dropout:{}, regularization_rate:{}, learning_rate:{}\".format(run_number, hparams[HP_NUM_UNITS_1], hparams[HP_NUM_UNITS_2],\n","                                                             hparams[HP_DROPOUT], hparams[HP_REGULARIZATION_RATE],\n","                                                             hparams[HP_LEARNING_RATE]))\n","          run_number += 1"]},{"cell_type":"markdown","metadata":{"id":"HQBpIvpDSyAD"},"source":["## Custom Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_fgzFUyY_Jh0"},"outputs":[],"source":["OPTIMIZER = Adam(learning_rate = 0.01)\n","METRIC = BinaryAccuracy()\n","METRIC_VAL = BinaryAccuracy()\n","EPOCHS = CONFIGURATION['N_EPOCHS']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aO_TeQKoqBkf"},"outputs":[],"source":["CURRENT_TIME = datetime.datetime.now().strftime('%d%m%y - %h%m%s')\n","CUSTOM_TRAIN_DIR = './logs/' + CURRENT_TIME + '/custom/train'\n","CUSTOM_VAL_DIR = './logs/' + CURRENT_TIME + '/custom/val'\n","\n","custom_train_writer = tf.summary.create_file_writer(CUSTOM_TRAIN_DIR)\n","custom_val_writer = tf.summary.create_file_writer(CUSTOM_VAL_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3toQq0HNQofo"},"outputs":[],"source":["@tf.function\n","def training_block(x_batch, y_batch):\n","  with tf.GradientTape() as recorder:\n","      y_pred = lenet_model(x_batch, training = True)\n","      loss = custom_bce(y_batch, y_pred)\n","\n","  #wandb.log({'loss':loss.numpy()})\n","  partial_derivatives = recorder.gradient(loss, lenet_model.trainable_weights)\n","  OPTIMIZER.apply_gradients(zip(partial_derivatives, lenet_model.trainable_weights))\n","  METRIC.update_state(y_batch, y_pred)\n","  return loss\n","\n","@tf.function\n","def val_block(x_batch_val, y_batch_val):\n","    y_pred_val = lenet_model(x_batch_val, training = False)\n","    loss_val = custom_bce(y_batch_val, y_pred_val)\n","    METRIC_VAL.update_state(y_batch_val, y_pred_val)\n","    return loss_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A8UMV43MXZyF"},"outputs":[],"source":["def neuralearn(model, loss_function, METRIC, VAL_METRIC, OPTIMIZER, train_dataset, val_dataset, EPOCHS):\n","  for epoch in range(EPOCHS):\n","    print(\"Training starts for epoch number {}\".format(epoch+1))\n","    for step, (x_batch, y_batch) in enumerate(train_dataset):\n","      loss = training_block(x_batch, y_batch)\n","      \n","    print(\"Training Loss\", loss)\n","    print(\"The accuracy is: \", METRIC.result())\n","\n","    with custom_train_writer.as_default():\n","      tf.summary.scalar('Training Loss', data = loss, step = epoch)\n","    with custom_train_writer.as_default():\n","      tf.summary.scalar('Training Accuracy', data = METRIC.result(), step = epoch)\n","      \n","    METRIC.reset_states()\n","\n","    for (x_batch_val, y_batch_val) in val_dataset:\n","      loss_val = val_block(x_batch_val, y_batch_val)\n","\n","    print(\"The Validation loss\", loss_val)\n","    print(\"The Validation accuracy is: \", METRIC_VAL.result())\n","\n","    with custom_val_writer.as_default():\n","      tf.summary.scalar('Validation Loss', data = loss_val, step = epoch)\n","    with custom_val_writer.as_default():\n","      tf.summary.scalar('Validation Accuracy', data = METRIC_VAL.result(), step = epoch)\n","      \n","    METRIC_VAL.reset_states()\n","  print(\"Training Complete!!!!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CkAe8ZV0YO9d"},"outputs":[],"source":["neuralearn(lenet_model, custom_bce, METRIC, METRIC_VAL, OPTIMIZER, train_dataset, val_dataset, EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EqTbzoj2266w"},"outputs":[],"source":["# image = cv2.imread('cell.jpg')\n","# print(image.shape)\n","# image = tf.expand_dims(image, axis = 0)\n","# print(image.shape)\n","\n","# lenet_model.predict(image)"]},{"cell_type":"markdown","metadata":{"id":"qdq-5nzgBgC1"},"source":["## Visualizations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nURZ0KN8SAAK"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qmgGVhNwJJ4F"},"outputs":[],"source":["tensorboard --logdir=logs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lKt3lx4N0hfv"},"outputs":[],"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train_loss', 'val_loss'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4FAk3gY0hg8"},"outputs":[],"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['train_accuracy', 'val_accuracy'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1h_6C48b86CN"},"source":["# **Model Evaluation and Testing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRGfTlSA-5Gp"},"outputs":[],"source":["test_dataset = test_dataset.batch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1lUnFwwm9bc"},"outputs":[],"source":["lenet_model.evaluate(test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"dyUnLjaOJRZN"},"source":["## Visualizing Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QAbnEi-StSqV"},"outputs":[],"source":["labels = []\n","inp = []\n","# for t in test_dataset:\n","#   print(t)\n","#   break\n","for x,y in test_dataset.as_numpy_iterator():\n","  labels.append(y)\n","  inp.append(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kzk8ziZM06PP"},"outputs":[],"source":["print(np.array(inp).shape)\n","print(np.array(inp)[:,0,...].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zz5CtEZLigm"},"outputs":[],"source":["labels = np.array([i[0] for i in labels])\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4wk_Vr8iOQN7"},"outputs":[],"source":["predicted = lenet_model.predict(np.array(inp)[:,0,...])\n","print(predicted[:,0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JdBB3_-RO2nf"},"outputs":[],"source":["threshold = 0.5\n","\n","cm = confusion_matrix(labels, predicted > threshold)\n","print(cm)\n","plt.figure(figsize=(8,8))\n","\n","sns.heatmap(cm, annot=True,)\n","plt.title('Confusion matrix - {}'.format(threshold))\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XFbX78RpN3iC"},"outputs":[],"source":["#tp: 1267.0000 - fp: 99.0000 - tn: 1298.0000 - fn: 93.0000"]},{"cell_type":"markdown","metadata":{"id":"X6iDg1tvHFkz"},"source":["## ROC Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZUiZnMGN-7-"},"outputs":[],"source":["fp, tp, thresholds = roc_curve(labels, predicted)\n","plt.plot(fp, tp)\n","plt.xlabel(\"False Positive rate\")\n","plt.ylabel(\"True Positive rate\")\n","\n","plt.grid()\n","\n","skip = 20\n","\n","for i in range(0, len(thresholds), skip):\n","  plt.text(fp[i], tp[i], thresholds[i])\n","  \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BNXfkonHEeT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k5Phk0rRm9dy"},"outputs":[],"source":["parasite_or_not(lenet_model.predict(test_dataset.take(1))[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0aFmzOJCOnOt"},"outputs":[],"source":["def parasite_or_not(x):\n","  if(x<0.5):\n","    return str('P')\n","  else:\n","    return str('U')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9vuhe3wm9gk"},"outputs":[],"source":["for i, (image, label) in enumerate(test_dataset.take(9)):\n","\n","  ax = plt.subplot(3, 3, i + 1)\n","  plt.imshow(image[0])\n","  plt.title(str(parasite_or_not(label.numpy()[0])) + \":\" + str(parasite_or_not(lenet_loaded_model.predict(image)[0][0])))\n","  \n","  plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXKMU54Im9jv"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"utvqGMT1Xvtv"},"source":["# Loading and Saving"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BkeTbJxZm9mS"},"outputs":[],"source":["lenet_model.save(\"lenet\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yykivbhcm9o-"},"outputs":[],"source":["lenet_loaded_model = tf.keras.models.load_model(\"lenets\")\n","lenet_loaded_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vKaCNEYm9rW"},"outputs":[],"source":["lenet_model.save(\"lenet.hdf5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hlCI1ibKm9t4"},"outputs":[],"source":["lenet_loaded_model = tf.keras.models.load_model(\"lenet.hdf5\")\n","lenet_loaded_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eVam3ZQ2m9wQ"},"outputs":[],"source":["lenet_model.save_weights(\"weights/lenet_weights\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ff3EohH2m9yi"},"outputs":[],"source":["lenet_weights_model = lenet_model.load_weights(\"weights/lenet_weights\")"]},{"cell_type":"markdown","metadata":{"id":"0Cr7sRFKtYvO"},"source":["## Saving to and Loading from Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVJGZOsMecr_"},"outputs":[],"source":["drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fgJf4GHecu8"},"outputs":[],"source":["!cp -r /content/lenet/ /content/drive/MyDrive/lenet_colab/ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5qR6IMXecxa"},"outputs":[],"source":["!cp -r /content/drive/MyDrive/lenet_colab/ /content/lenet_colab/ "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJELckJC02YI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPcnmqoJcL7W"},"outputs":[],"source":["image_1 = cv2.resize(cv2.imread('car.jpg'), (2560, 1440))/255\n","image_2 = cv2.resize(cv2.imread('train.jpg'), (2560, 1440))/255\n","print(image_1.shape, image_2.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfTgp71H4uwj"},"outputs":[],"source":["from matplotlib.pyplot import figure\n","\n","figure(figsize=(100, 100), dpi=80)\n","\n","lamda = 0.6\n","image = lamda*image_1 + (1-lamda)*image_2\n","\n","plt.imshow(image)\n","plt.axis('off')\n","plt.savefig('image.jpg')"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":["DK7_p02_b6_m","-1QWh3KjbsuJ","3BUZMRuhV-HL","z_RZU3vxG2Aj","im-Eo6tvHgmM","IylKvmx5LUCR","PTW0fKw313gt","TeVM_g7JsaQr","AsB9YnCuPITj","peB3_ExnPQl0","hNqYhbE3pCzJ","kbm2WoMpfXod","11Wz41MHkzTu","3arkQ973eIjM","xgF_fkT-qngT","20ultY2FdfyX","413m-l0pttrt","lLaHf-B12OH8","P04zuKYv_hex","yvoXsM8zC6bD","ZEau-uvfRWA5","-t5zQwWckCS9","Rrm7NNzuDd5k","_AcriqBA2IU4","2bEezFeL_8tr","-0mircHogrvl","JhawCc8jf8JB","J3I7Zhyufjsf","DxMyYeM-DmlM","zzS9pcnOPRva","HQBpIvpDSyAD","qdq-5nzgBgC1","1h_6C48b86CN","dyUnLjaOJRZN","X6iDg1tvHFkz","utvqGMT1Xvtv","0Cr7sRFKtYvO"],"machine_shape":"hm","provenance":[{"file_id":"1uUH-asz3CFxlvld8uGx-m3crr4Iepp3u","timestamp":1673770117165}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}