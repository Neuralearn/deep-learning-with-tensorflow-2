{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEYsHlbQ9MSIK58KUUGle3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"g2lR_wjyQBmp"},"outputs":[],"source":["import tensorflow as tf### models\n","import numpy as np### math computations\n","import matplotlib.pyplot as plt### plotting bar chart\n","import sklearn### machine learning library\n","import cv2## image processing\n","import scipy.io\n","import tensorflow_probability as tfp\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n","                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n","                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n","                                     RandomContrast, Rescaling, Resizing, Reshape,LeakyReLU)\n","from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n","from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n","                                        ModelCheckpoint, ReduceLROnPlateau)\n","from tensorflow.keras.regularizers import L2, L1\n","from tensorflow.keras.initializers import RandomNormal"]},{"cell_type":"markdown","source":["# DATA PREPARATION"],"metadata":{"id":"kOZ4KwY3TbFa"}},{"cell_type":"code","source":["IN_X,IN_Y=768,1024\n","OUT_X,OUT_Y=96,128\n","SUBSAMPLING_FACTOR=IN_X//OUT_X"],"metadata":{"id":"lxmP8WGGTZBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gauss_distribution(x,u=0,sigma=10):\n","    return np.expand_dims(1/(np.sqrt(2*np.pi*(sigma**2)))*np.exp(-(0.5)*(((x-u)/sigma)**2)),axis=0)"],"metadata":{"id":"ACZxPhNSTiyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_density_map_gaussian(im,points,gaussian_radius=4):\n","    density_map=np.zeros((OUT_X,OUT_Y))\n","    w,h=OUT_Y,OUT_X\n","    num_gt=len(points)\n","    \n","    for point in points:\n","        point=np.round(point).astype(int)\n","        point[0],point[1]=min(h-1,point[1]),min(w-1,point[0])\n","        x=np.linspace(-gaussian_radius,gaussian_radius,(gaussian_radius*2)+1)\n","        gaussian_map=np.multiply(gauss_distribution(x),gauss_distribution(x).T)\n","        gaussian_map/=np.sum(gaussian_map)\n","        \n","        x_left,x_right,y_up,y_down=0,gaussian_map.shape[1],0,gaussian_map.shape[0]\n","        if point[1]<gaussian_radius:\n","            x_left=gaussian_radius-point[1]\n","        if point[0]<gaussian_radius:\n","            y_up=gaussian_radius-point[0]\n","        if point[1]+gaussian_radius>=w:\n","            x_right=gaussian_map.shape[1]-(gaussian_radius+point[1]-w)-1\n","        if point[0]+gaussian_radius>=h:\n","            y_down=gaussian_map.shape[0]-(gaussian_radius+point[0]-h)-1\n","        density_map[\n","            max(0,point[0]-gaussian_radius):min(density_map.shape[0],point[0]+gaussian_radius+1),\n","            max(0,point[1]-gaussian_radius):min(density_map.shape[1],point[1]+gaussian_radius+1),\n","        ]+=gaussian_map[y_up:y_down,x_left:x_rigtht]\n","    density_map/=np.sum(density_map/len(points))\n","    return density_map"],"metadata":{"id":"lfQg3N0eTZD1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__ (self, images, maps, batch_size,SUBSAMPLING_FACTOR=8):\n","\n","        self.images = images\n","        self.maps = maps\n","        self.batch_size = batch_size\n","        self.train_image_list=os.listdir(images)\n","        self.SUBSAMPLING_FACTOR=SUBSAMPLING_FACTOR\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.train_image_list)/self.batch_size))\n","  \n","    def __getitem__(self, idx):\n","        x,y = self.__data_generation(idx)\n","        return x,y\n","  \n","    def __data_generation(self, idx):\n","        x = []\n","        y = []\n","\n","        for j in range(idx*self.batch_size, (idx+1)*self.batch_size):\n","            \n","            im_array=img_to_array(load_img(self.images+os.listdir(self.images)[j],target_size=(IN_X,IN_Y)))\n","            im_array/=255.\n","            im_array[:,:,0]=(im_array[:,:,0]-np.mean(im_array[:,:,0]))/np.std(im_array[:,:,0])\n","            im_array[:,:,1]=(im_array[:,:,1]-np.mean(im_array[:,:,1]))/np.std(im_array[:,:,1])\n","            im_array[:,:,2]=(im_array[:,:,2]-np.mean(im_array[:,:,2]))/np.std(im_array[:,:,2])\n","            x.append(im_array)\n","            mat=scipy.io.loadmat(self.maps+os.listdir(self.maps)[j])\n","            points=mat['image_info'][0][0][0][0][0]\n","            points/=self.SUBSAMPLING_FACTOR\n","            \n","            density_map_present=get_density_map_gaussian(im_array,points,sigma=5)\n","            y.append(density_map_present)\n","    return tf.convert_to_tensor(x),tf.convert_to_tensor(y)"],"metadata":{"id":"IyICjrsjTZGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images='...'\n","train_maps='...'\n","val_images='...'\n","val_maps='...'\n","\n","LR=1e-4\n","BATCH_SIZE=1\n","EPOCH=1000"],"metadata":{"id":"MEmDHPHrTnrr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_gen = DataGenerator(images, maps,BATCH_SIZE,INPUT_DIM)\n","#val_gen = DataGenerator(val_images, val_maps,BATCH_SIZE,INPUT_DIM)"],"metadata":{"id":"GLCoJNJrTnuN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MODELING"],"metadata":{"id":"E5Hzk0j4TqLM"}},{"cell_type":"code","source":["def get_base_model():\n","    base_model = VGG16(\n","        weights='imagenet',\n","        input_shape=(INPUT_DIM,INPUT_DIM,3),\n","        include_top=False,)\n","    \n","    block4_conv3=[base_model.get_layer(layer_name).output for layer_name in [\"block4_conv3\"]]\n","    \n","    return Model(\n","        inputs=[base_model.inputs],outputs=[block4_conv3]\n","    )\n","\n","get_base_model().summary()"],"metadata":{"id":"jfGjAqBVTnwV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs=tf.keras.Input(shape=(IN_X,IN_Y,3))\n","x=get_base_model()(inputs)\n","init=RandomNormal(0.01)\n","\n","x=Conv2D(512, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n","x=Conv2D(512, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n","x=Conv2D(512, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n","x=Conv2D(256, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n","x=Conv2D(128, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n","x=Conv2D(64, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n","x=Conv2D(1, (1,1), activation = 'relu', dilation_rate=1,kernel_iniitalizer=init,padding='same')(x)\n","\n","out=Reshape((96,128))(x)\n","model=tf.keras.Model(inputs=inputs,outputs=out)\n","model.summary()"],"metadata":{"id":"DPmTIVQ9Tnys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n","    optimizer = Adam(learning_rate = LR),\n","    metrics='accuracy',\n","    run_eagerly = True,\n",")"],"metadata":{"id":"YT-kjG1JTZI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_filepath='...'\n","callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='loss',\n","    mode='min',\n","    save_best_only=True\n",")"],"metadata":{"id":"1QaRkOB0TyNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    train_gen,\n","    verbose=1,\n","    shuffle=True,\n","    epochs=EPOCH,\n","    callbacks=[callback])"],"metadata":{"id":"aCJsE-CCTyQC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TESTING"],"metadata":{"id":"W8c53yULT1D7"}},{"cell_type":"code","source":["IN ='...'\n","\n","im_array=img_to_array(load_img(train_image+IN_'.jpg',target_size=(IN_X,IN_Y)))\n","im_array/=255.\n","im_array[:,:,0]=(im_array[:,:,0]-np.mean(im_array[:,:,0]))/np.std(im_array[:,:,0])\n","im_array[:,:,1]=(im_array[:,:,1]-np.mean(im_array[:,:,1]))/np.std(im_array[:,:,1])\n","im_array[:,:,2]=(im_array[:,:,2]-np.mean(im_array[:,:,2]))/np.std(im_array[:,:,2])\n","\n","plt.figure(figsize=(20,12))\n","plt.imhow(im_array)\n","\n","output=mode.predict(tf.expand_dims(im_array,axis=0))\n","output=np.reshape(output,(OUT_X,OUT_Y))\n","\n","n_people=np.sum(output)\n","mat=scipy.io.loadmat(train_maps+'GT_'+IN+'.mat')\n","points=mat['image_info'][0][0][0][0][0]\n","points/=SUBSAMPLING_FACTOR\n","\n","num_gt=np.squeeze(points).shape[0]\n","print(\"The actual number of people is=\",num_gt)\n","print(\"The predicted number of people is =\",n_people)\n","\n","plt.figure(figsize=(20,12))\n","plt.imshow(output)"],"metadata":{"id":"GrVfcr8OT0YF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jOIrzCOgT0aj"},"execution_count":null,"outputs":[]}]}